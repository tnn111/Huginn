#!/usr/bin/env python3
"""
Extract bibliographical references from ENIGMA publications page.
Usage: python extract_enigma_refs.py [html_file_or_url]
"""
import re
import sys

def fetch_page(url):
    """Fetch webpage content (note: may require requests library)"""
    try:
        from urllib.request import Request, urlopen
        req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        return urlopen(req).read().decode('utf-8')
    except:
        print("Network access restricted or urllib not available")
        return None

def extract_references(html_content):
    """Recursively extract all bibliographical references from HTML"""
    # Remove HTML tags
    text = re.sub(r'<[^>]+>', '\n', html_content)
    text = re.sub(r'&[^;]+;', ' ', text)
    
    refs = []
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    
    i = 0
    while i < len(lines):
        line = lines[i]
        
        # Match reference start: Author(s) (Year)
        if re.match(r'^[A-Z][A-Za-z\-]+[,\s]+.*?\(\d{4}\)', line):
            ref_parts = [line]
            i += 1
            
            # Collect lines until next reference or section header
            while i < len(lines):
                next_line = lines[i]
                
                # Stop at section headers or new references
                if re.match(r'^(20\d{2}|Synergistic|Books)', next_line):
                    break
                if (re.match(r'^[A-Z][A-Za-z\-]+[,\s]+.*?\(\d{4}\)', next_line) and 
                    not any(x in next_line for x in ['[DOI]', '[doi]', 'OSTI'])):
                    break
                
                ref_parts.append(next_line)
                i += 1
                
                # Check if this might be the last line (has OSTI but no more content follows)
                if any(marker in next_line for marker in ['DOI]:', 'doi]:', 'PMID]:', 'OSTI:']):
                    # Peek ahead to see if there's continuation
                    if i < len(lines) and not re.match(r'^[A-Z][A-Za-z\-]+[,\s]+.*?\(\d{4}\)', lines[i]):
                        # Include next line if it's not a new reference
                        if i < len(lines) and not re.match(r'^(20\d{2}|Synergistic|Books)', lines[i]):
                            ref_parts.append(lines[i])
                            i += 1
                    break
            
            reference = ' '.join(ref_parts)
            if len(reference) > 80:  # Filter short spurious matches
                refs.append(reference)
        else:
            i += 1
    
    return refs

def main():
    if len(sys.argv) > 1:
        arg = sys.argv[1]
        if arg.startswith('http'):
            html = fetch_page(arg)
            if not html:
                print("Failed to fetch URL")
                return
        else:
            with open(arg) as f:
                html = f.read()
    else:
        html = sys.stdin.read()
    
    refs = extract_references(html)
    
    print(f"\n{'='*80}")
    print(f"Extracted {len(refs)} bibliographical references")
    print(f"{'='*80}\n")
    
    for i, ref in enumerate(refs, 1):
        print(f"[{i}] {ref}\n")
    
    print(f"{'='*80}")
    print(f"Total: {len(refs)} references extracted")
    print(f"{'='*80}\n")

if __name__ == '__main__':
    main()
