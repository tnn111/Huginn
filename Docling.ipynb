{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a32373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.document_converter import PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.pipeline_options import TableFormerMode\n",
    "\n",
    "from docling_core.types.doc.base import ImageRefMode\n",
    "from docling_core.types.doc.document import PictureItem\n",
    "from docling_core.types.doc.document import TableItem\n",
    "from docling_core.types.doc.document import TextItem\n",
    "from docling_core.types.doc.document import DoclingDocument\n",
    "from docling.backend.docling_parse_v4_backend import DoclingParseV4DocumentBackend\n",
    "from docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = True\n",
    "pipeline_options.do_table_structure = True\n",
    "pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE\n",
    "pipeline_options.do_code_enrichment = True\n",
    "pipeline_options.do_formula_enrichment = True\n",
    "pipeline_options.do_picture_classification = True\n",
    "\n",
    "output_dir = Path('Output')\n",
    "output_dir.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bba5b497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 17:31:08,527 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-06 17:31:08,529 - INFO - Going to convert document batch...\n",
      "2025-11-06 17:31:08,529 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 0c59f2efc0f49e77e021b96930f51155\n",
      "2025-11-06 17:31:08,534 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-06 17:31:08,535 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-11-06 17:31:08,555 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-11-06 17:31:09,119 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-06 17:31:09,121 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-11-06 17:31:09,125 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2025-11-06 17:31:09,126 - INFO - easyocr cannot be used because it is not installed.\n",
      "2025-11-06 17:31:09,211 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,220 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,229 [RapidOCR] download_file.py:60: File exists and is valid: /home/torben/Huginn/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,230 [RapidOCR] torch.py:54: Using /home/torben/Huginn/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,331 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,332 [RapidOCR] download_file.py:60: File exists and is valid: /home/torben/Huginn/.venv/lib/python3.12/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,332 [RapidOCR] torch.py:54: Using /home/torben/Huginn/.venv/lib/python3.12/site-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,368 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,383 [RapidOCR] download_file.py:60: File exists and is valid: /home/torben/Huginn/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-06 17:31:09,383 [RapidOCR] torch.py:54: Using /home/torben/Huginn/.venv/lib/python3.12/site-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "2025-11-06 17:31:09,709 - INFO - Auto OCR model selected rapidocr with torch.\n",
      "2025-11-06 17:31:09,711 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-11-06 17:31:10,413 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-11-06 17:31:10,651 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-11-06 17:31:11,345 - INFO - Processing document 2501.17887v1.pdf\n",
      "2025-11-06 17:31:12,447 - INFO - Finished converting document 2501.17887v1.pdf in 4.17 sec.\n"
     ]
    }
   ],
   "source": [
    "docling_paper = 'https://arxiv.org/pdf/2501.17887'\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    allowed_formats = [InputFormat.PDF],\n",
    "    format_options = {\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options = pipeline_options, backend = PyPdfiumDocumentBackend),\n",
    "        }\n",
    ")\n",
    "\n",
    "result = converter.convert(docling_paper)\n",
    "doc = result.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f184e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion\n",
      "\n",
      "Nikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar\n",
      "\n",
      "IBM Research, Ruschlikon, Switzerland ¨ ¨\n",
      "\n",
      "Please send correspondence to: deepsearch-core@zurich.ibm.com\n",
      "\n",
      "## Abstract\n",
      "\n",
      "We introduce Docling, an easy-to-use, self-contained, MITlicensed, open-source toolkit for document conversion, that can parse several types of popular document formats into a unified, richly structured representation. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. Docling is released as a Python package and can be used as a Python API or as a CLI tool. Docling's modular architecture and efficient document representation make it easy to implement extensions, new features, models, and customizations. Docling has been already integrated in other popular open-source frameworks (e.g., LangChain, LlamaIndex, spaCy), making it a natural fit for the processing of documents and the development of high-end applications. The open-source community has fully engaged in using, promoting, and developing for Docling, which gathered 10k stars on GitHub in less than a month and was reported as the No. 1 trending repository in GitHub worldwide in November 2024.\n",
      "\n",
      "Repository — https://github.com/DS4SD/docling\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Converting documents back into a unified machineprocessable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which often discards structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs, Office documents, and scanned document images has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, SaaS offerings on hyperscalers (Auer et al. 2022) and most recently, multimodal vision-language models. Typically, they incur a cost (e.g., for licensing or LLM inference) and cannot be run easily on local hardware. Meanwhile, only a handful of different open-source tools cover PDF, MS Word, MS PowerPoint, Images, or HTML conversion, leaving a significant feature and quality gap to proprietary solutions.\n",
      "\n",
      "* These authors contributed equally.\n",
      "\n",
      "Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\n",
      "\n",
      "With Docling, we recently open-sourced a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition that we developed and presented in the recent past (Livathinos et al. 2021; Pfitzmann et al. 2022; Lysak et al. 2023). Docling is designed as a simple, self-contained Python library with permissive MIT license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models. Since its launch in July 2024, Docling has attracted considerable attention in the AI developer community and ranks top on GitHub's monthly trending repositories with more than 10,000 stars at the time of writing. On October 16, 2024, Docling reached a major milestone with version 2, introducing several new features and concepts, which we outline in this updated technical report, along with details on its architecture, conversion speed benchmarks, and comparisons to other open-source assets.\n",
      "\n",
      "The following list summarizes the features currently available on Docling:\n",
      "\n",
      "- Parses common document formats (PDF, Images, MS Office formats, HTML) and exports to Markdown, JSON, and HTML.\n",
      "- Applies advanced AI for document understanding, including detailed page layout, OCR, reading order, figure extraction, and table structure recognition.\n",
      "- Establishes a unified DoclingDocument data model for rich document representation and operations.\n",
      "- Provides fully local execution capabilities making it suitable for sensitive data and air-gapped environments.\n",
      "- Has an ecosystem of plug-and-play integrations with prominent generative AI development frameworks, including LangChain and LlamaIndex.\n",
      "- Can leverage hardware accelerators such as GPUs.\n",
      "\n",
      "## 2 State of the Art\n",
      "\n",
      "Document conversion is a well-established field with numerous solutions already available on the market. These solutions can be categorized along several key dimensions, including open vs. closed source, permissive vs. restrictive licensing, Web APIs vs. local code deployment, susceptibility\n",
      "\n",
      "Figure 1: Sketch of Docling's pipelines and usage model. Both PDF pipeline and simple pipeline build up a DoclingDocument representation, which can be further enriched. Downstream applications can utilize Docling's API to inspect, export, or chunk the document for various purposes.\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "to hallucinations, conversion quality, time-to-solution, and compute resource requirements.\n",
      "\n",
      "The most popular conversion tools today leverage visionlanguage models (VLMs), which process page images to text and markup directly. Among proprietary solutions, prominent examples include GPT-4o (OpenAI), Claude (Anthropic), and Gemini (Google). In the open-source domain, LLaVA-based models, such as LLaVA-next, are noteworthy. However, all generative AI-based models face two significant challenges. First, they are prone to hallucinations, i.e., their output may contain false information which is not present in the source document — a critical issue when faithful transcription of document content is required. Second, t\n"
     ]
    }
   ],
   "source": [
    "md_out = doc.export_to_markdown()\n",
    "print(f'{md_out[ : 6000]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a8d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document title: 2501.17887v1\n",
      "Number of pages: 8\n",
      "Number of tables: 1\n",
      "Number of pictures: 6\n",
      "Document structure\n",
      "  - SectionHeaderItem: Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion\n",
      "  - TextItem: Nikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de L\n",
      "  - TextItem: IBM Research, Ruschlikon, Switzerland ¨ ¨\n",
      "  - TextItem: Please send correspondence to: deepsearch-core@zurich.ibm.com\n",
      "  - SectionHeaderItem: Abstract\n",
      "  - TextItem: We introduce Docling, an easy-to-use, self-contained, MITlicensed, open-source toolkit for document conversion, that can parse several types of popular document formats into a unified, richly structur\n",
      "  - TextItem: Repository — https://github.com/DS4SD/docling\n",
      "  - SectionHeaderItem: 1 Introduction\n",
      "  - TextItem: Converting documents back into a unified machineprocessable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characte\n",
      "  - TextItem: * These authors contributed equally.\n",
      "  - TextItem: Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\n",
      "  - TextItem: With Docling, we recently open-sourced a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure re\n",
      "  - TextItem: The following list summarizes the features currently available on Docling:\n",
      "    - ListItem: Parses common document formats (PDF, Images, MS Office formats, HTML) and exports to Markdown, JSON, and HTML.\n",
      "    - ListItem: Applies advanced AI for document understanding, including detailed page layout, OCR, reading order, figure extraction, and table structure recognition.\n",
      "    - ListItem: Establishes a unified DoclingDocument data model for rich document representation and operations.\n",
      "    - ListItem: Provides fully local execution capabilities making it suitable for sensitive data and air-gapped environments.\n",
      "    - ListItem: Has an ecosystem of plug-and-play integrations with prominent generative AI development frameworks, including LangChain and LlamaIndex.\n",
      "    - ListItem: Can leverage hardware accelerators such as GPUs.\n",
      "  - SectionHeaderItem: 2 State of the Art\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document title: {doc.name}\")\n",
    "print(f\"Number of pages: {len(doc.pages)}\")\n",
    "print(f\"Number of tables: {len(doc.tables)}\")\n",
    "print(f\"Number of pictures: {len(doc.pictures)}\")\n",
    "\n",
    "print('Document structure')\n",
    "for i, (item, level) in enumerate(doc.iterate_items()):\n",
    "    if i < 20:\n",
    "        item_type = type(item).__name__\n",
    "        text_preview = item.text[:200] if hasattr(item, 'text') else 'N/A'\n",
    "        print(f'{\"  \" * level}- {item_type}: {text_preview}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e4a0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.save_as_json(output_dir / 'docling_paper.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0548c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huginn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
